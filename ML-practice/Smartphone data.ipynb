{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wpghk\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', module='sklearn')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "# Type Path\n",
    "data_path = [r'C:\\Users\\wpghk\\ai_data']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filepath = os.sep.join(data_path + ['Human_Activity_Recognition_Using_Smartphones_Data.csv'])\n",
    "data = pd.read_csv(filepath, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['Activity'] = le.fit_transform(data.Activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "feature_cols = data.columns[:-1]\n",
    "corr_values = data[feature_cols].corr()\n",
    "# Get the split indexes\n",
    "strat_shuf_split = StratifiedShuffleSplit(n_splits=1, \n",
    "                                          test_size=0.3, \n",
    "                                          random_state=42)\n",
    "\n",
    "train_idx, test_idx = next(strat_shuf_split.split(data[feature_cols], data.Activity))\n",
    "\n",
    "# Create the dataframes\n",
    "X_train = data.loc[train_idx, feature_cols]\n",
    "y_train = data.loc[train_idx, 'Activity']\n",
    "\n",
    "X_test  = data.loc[test_idx, feature_cols]\n",
    "y_test  = data.loc[test_idx, 'Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(classifier, X_train, y_train, X_test, y_test, train = True):\n",
    "    print(\"-\"*100)\n",
    "    if train == True:\n",
    "        y_pred = classifier.predict(X_train)\n",
    "        print(\"Training result:\\n\")\n",
    "        print(\"Accuracy Score: {0:.4f}\\n\".format(accuracy_score(y_train, y_pred)))\n",
    "        print(\"Classification Report:\\n{}\\n\".format(classification_report(y_train, y_pred)))\n",
    "        print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_train, y_pred)))\n",
    "        #res = cross_val_score(classifier, X_train, y_train, cv = 10, n_jobs= -1, scoring =\"accuracy\")\n",
    "        #print(\"Average Accuracy:\\t{0:.4f}\\n\".format(res.mean()))\n",
    "        #print(\"Standard Deviation:\\t{0:.4f}\".format(res.std()))\n",
    "    elif train == False:\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        print(\"Test result:\\n\")\n",
    "        print(\"Accuracy Score: {0:.4f}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "        print(\"Classification Report:\\n{}\\n\".format(classification_report(y_test, y_pred)))\n",
    "        print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Training result:\n",
      "\n",
      "Accuracy Score: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1361\n",
      "          1       1.00      1.00      1.00      1244\n",
      "          2       1.00      1.00      1.00      1334\n",
      "          3       1.00      1.00      1.00      1205\n",
      "          4       1.00      1.00      1.00       984\n",
      "          5       1.00      1.00      1.00      1081\n",
      "\n",
      "avg / total       1.00      1.00      1.00      7209\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1361    0    0    0    0    0]\n",
      " [   0 1244    0    0    0    0]\n",
      " [   0    0 1334    0    0    0]\n",
      " [   0    0    0 1205    0    0]\n",
      " [   0    0    0    0  984    0]\n",
      " [   0    0    0    0    0 1081]]\n",
      "\n",
      "Average Accuracy:\t0.9773\n",
      "\n",
      "Standard Deviation:\t0.0055\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.9764\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       583\n",
      "          1       0.96      0.97      0.96       533\n",
      "          2       0.97      0.96      0.97       572\n",
      "          3       0.99      0.97      0.98       517\n",
      "          4       0.97      0.98      0.97       422\n",
      "          5       0.96      0.98      0.97       463\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3090\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[581   0   0   0   0   2]\n",
      " [  0 515  17   0   0   1]\n",
      " [  0  21 551   0   0   0]\n",
      " [  0   0   0 502   5  10]\n",
      " [  0   0   0   3 414   5]\n",
      " [  0   0   0   0   9 454]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 50, criterion='entropy',random_state = 42, n_jobs=-1)\n",
    "random_forest.fit(X_train, y_train)\n",
    "print_score(random_forest ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(random_forest ,X_train,y_train,X_test,y_test, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.9990\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1361\n",
      "          1       1.00      1.00      1.00      1244\n",
      "          2       1.00      1.00      1.00      1334\n",
      "          3       1.00      1.00      1.00      1205\n",
      "          4       1.00      1.00      1.00       984\n",
      "          5       1.00      1.00      1.00      1081\n",
      "\n",
      "avg / total       1.00      1.00      1.00      7209\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1361    0    0    0    0    0]\n",
      " [   0 1242    2    0    0    0]\n",
      " [   0    5 1329    0    0    0]\n",
      " [   0    0    0 1205    0    0]\n",
      " [   0    0    0    0  984    0]\n",
      " [   0    0    0    0    0 1081]]\n",
      "\n",
      "Average Accuracy:\t0.9821\n",
      "\n",
      "Standard Deviation:\t0.0039\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.9845\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99       583\n",
      "          1       0.97      0.97      0.97       533\n",
      "          2       0.98      0.97      0.98       572\n",
      "          3       1.00      1.00      1.00       517\n",
      "          4       0.95      1.00      0.97       422\n",
      "          5       1.00      0.99      0.99       463\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3090\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[577   0   0   0   6   0]\n",
      " [  1 516   9   0   7   0]\n",
      " [  0  15 555   0   2   0]\n",
      " [  0   0   0 516   1   0]\n",
      " [  0   0   0   1 421   0]\n",
      " [  0   0   0   0   6 457]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "print_score(svm ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(svm ,X_train,y_train,X_test,y_test, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.9877\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1361\n",
      "          1       0.96      0.97      0.97      1244\n",
      "          2       0.97      0.97      0.97      1334\n",
      "          3       1.00      1.00      1.00      1205\n",
      "          4       1.00      1.00      1.00       984\n",
      "          5       1.00      1.00      1.00      1081\n",
      "\n",
      "avg / total       0.99      0.99      0.99      7209\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1361    0    0    0    0    0]\n",
      " [   2 1206   36    0    0    0]\n",
      " [   0   45 1289    0    0    0]\n",
      " [   0    0    0 1203    1    1]\n",
      " [   0    0    0    3  981    0]\n",
      " [   0    0    0    0    1 1080]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.9673\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       583\n",
      "          1       0.91      0.92      0.91       533\n",
      "          2       0.93      0.92      0.92       572\n",
      "          3       0.99      1.00      0.99       517\n",
      "          4       1.00      0.98      0.99       422\n",
      "          5       0.99      1.00      0.99       463\n",
      "\n",
      "avg / total       0.97      0.97      0.97      3090\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[583   0   0   0   0   0]\n",
      " [  1 489  42   0   0   1]\n",
      " [  0  47 524   0   0   1]\n",
      " [  0   0   0 516   0   1]\n",
      " [  0   0   0   5 414   3]\n",
      " [  0   0   0   0   0 463]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print_score(knn ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(knn ,X_train,y_train,X_test,y_test, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.9875\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1361\n",
      "          1       0.96      0.97      0.96      1244\n",
      "          2       0.97      0.97      0.97      1334\n",
      "          3       1.00      1.00      1.00      1205\n",
      "          4       1.00      1.00      1.00       984\n",
      "          5       1.00      1.00      1.00      1081\n",
      "\n",
      "avg / total       0.99      0.99      0.99      7209\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1361    0    0    0    0    0]\n",
      " [   0 1201   43    0    0    0]\n",
      " [   0   45 1289    0    0    0]\n",
      " [   0    0    0 1204    0    1]\n",
      " [   0    0    0    0  984    0]\n",
      " [   0    0    0    1    0 1080]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.9841\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       583\n",
      "          1       0.96      0.96      0.96       533\n",
      "          2       0.96      0.96      0.96       572\n",
      "          3       1.00      1.00      1.00       517\n",
      "          4       1.00      1.00      1.00       422\n",
      "          5       1.00      1.00      1.00       463\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3090\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[583   0   0   0   0   0]\n",
      " [  0 512  21   0   0   0]\n",
      " [  0  22 550   0   0   0]\n",
      " [  0   0   0 515   1   1]\n",
      " [  0   0   0   1 420   1]\n",
      " [  0   0   0   1   1 461]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print_score(logreg ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(logreg ,X_train,y_train,X_test,y_test, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Training result:\n",
      "\n",
      "Accuracy Score: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1361\n",
      "          1       1.00      1.00      1.00      1244\n",
      "          2       1.00      1.00      1.00      1334\n",
      "          3       1.00      1.00      1.00      1205\n",
      "          4       1.00      1.00      1.00       984\n",
      "          5       1.00      1.00      1.00      1081\n",
      "\n",
      "avg / total       1.00      1.00      1.00      7209\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1361    0    0    0    0    0]\n",
      " [   0 1244    0    0    0    0]\n",
      " [   0    0 1334    0    0    0]\n",
      " [   0    0    0 1205    0    0]\n",
      " [   0    0    0    0  984    0]\n",
      " [   0    0    0    0    0 1081]]\n",
      "\n",
      "Average Accuracy:\t0.9284\n",
      "\n",
      "Standard Deviation:\t0.0093\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.9298\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       583\n",
      "          1       0.91      0.91      0.91       533\n",
      "          2       0.92      0.91      0.91       572\n",
      "          3       0.94      0.93      0.93       517\n",
      "          4       0.90      0.95      0.92       422\n",
      "          5       0.91      0.87      0.89       463\n",
      "\n",
      "avg / total       0.93      0.93      0.93      3090\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[583   0   0   0   0   0]\n",
      " [  0 485  47   0   0   1]\n",
      " [  0  50 522   0   0   0]\n",
      " [  0   0   0 479  13  25]\n",
      " [  0   0   0   6 400  16]\n",
      " [  0   0   0  27  32 404]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(405, 21)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print_score(dt ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(dt ,X_train,y_train,X_test,y_test, train = False)\n",
    "dt.tree_.node_count, dt.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-42cb1311c505>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgnb\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    602\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[0;32m    603\u001b[0m                                        dtype=np.float64)\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "print_score(gnb ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(gnb ,X_train,y_train,X_test,y_test, train = False)\n",
    "print_score(bnb ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(bnb ,X_train,y_train,X_test,y_test, train = False)\n",
    "print_score(mnb ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(mnb ,X_train,y_train,X_test,y_test, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
