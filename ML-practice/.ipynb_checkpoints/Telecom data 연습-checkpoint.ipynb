{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orange_Telecom_Churn_Data 불러오기\n",
    "\n",
    "state , area_code, phone_number 불필요한 데이터 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "# Type Path\n",
    "data_path = [r'C:\\Users\\wpghk\\ai_data']\n",
    "\n",
    "import pandas as pd \n",
    "# Import the data using the file path \n",
    "filepath = os.sep.join(data_path + ['Orange_Telecom_Churn_Data.csv']) \n",
    "data = pd.read_csv(filepath) \n",
    "\n",
    "# Type your source code\n",
    "data.drop(['state', 'area_code', 'phone_number'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wpghk\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', module='sklearn')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "\n",
    "for col in ['intl_plan', 'voice_mail_plan', 'churned']:\n",
    "    data[col] = lb.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc = MinMaxScaler()\n",
    "\n",
    "data = pd.DataFrame(msc.fit_transform(data),  # this is an np.array, not a dataframe.\n",
    "                    columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [x for x in data.columns if x != 'churned']\n",
    "\n",
    "\n",
    "# Split the data into two parts with 1500 points in the test data\n",
    "# This creates a generator\n",
    "strat_shuff_split = StratifiedShuffleSplit(n_splits=1, test_size=1500, random_state=42)\n",
    "\n",
    "# Get the index values from the generator\n",
    "train_idx, test_idx = next(strat_shuff_split.split(data[feature_cols], data['churned']))\n",
    "\n",
    "# Create the data sets\n",
    "X_train = data.loc[train_idx, feature_cols]\n",
    "y_train = data.loc[train_idx, 'churned']\n",
    "\n",
    "X_test = data.loc[test_idx, feature_cols]\n",
    "y_test = data.loc[test_idx, 'churned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(classifier, X_train, y_train, X_test, y_test, train = True):\n",
    "    if train == True:\n",
    "        y_pred = classifier.predict(X_train)\n",
    "        print(\"Training result:\\n\")\n",
    "        print(\"Accuracy Score: {0:.4f}\\n\".format(accuracy_score(y_train, y_pred)))\n",
    "        print(\"Classification Report:\\n{}\\n\".format(classification_report(y_train, y_pred)))\n",
    "        print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_train, y_pred)))\n",
    "        res = cross_val_score(classifier, X_train, y_train, cv = 10, n_jobs= -1, scoring =\"accuracy\")\n",
    "        print(\"Average Accuracy:\\t{0:.4f}\\n\".format(res.mean()))\n",
    "        print(\"Standard Deviation:\\t{0:.4f}\".format(res.std()))\n",
    "    elif train == False:\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        print(\"Test result:\\n\")\n",
    "        print(\"Accuracy Score: {0:.4f}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "        print(\"Classification Report:\\n{}\\n\".format(classification_report(y_test, y_pred)))\n",
    "        print(\"Confusion Matrix:\\n{}\\n\".format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model\n",
    "\n",
    "    Random Forest Classifier\n",
    "    Support Vector Classifier\n",
    "    KNeighbors Classifier\n",
    "    Naive Bayes\n",
    "    Logistic Regression\n",
    "    Decision Tree Classifier\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 50, criterion='entropy',random_state = 42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth = 11)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.9997\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3005\n",
      "          1       1.00      1.00      1.00       495\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3005    0]\n",
      " [   1  494]]\n",
      "\n",
      "Average Accuracy:\t0.9506\n",
      "\n",
      "Standard Deviation:\t0.0085\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.9573\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98      1288\n",
      "          1       0.96      0.73      0.83       212\n",
      "\n",
      "avg / total       0.96      0.96      0.95      1500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1281    7]\n",
      " [  57  155]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(random_forest ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(random_forest ,X_train,y_train,X_test,y_test, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.8586\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      1.00      0.92      3005\n",
      "        1.0       0.00      0.00      0.00       495\n",
      "\n",
      "avg / total       0.74      0.86      0.79      3500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3005    0]\n",
      " [ 495    0]]\n",
      "\n",
      "Average Accuracy:\t0.8586\n",
      "\n",
      "Standard Deviation:\t0.0010\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.8587\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      1.00      0.92      1288\n",
      "        1.0       0.00      0.00      0.00       212\n",
      "\n",
      "avg / total       0.74      0.86      0.79      1500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1288    0]\n",
      " [ 212    0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(svm ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(svm ,X_train,y_train,X_test,y_test, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.9414\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.99      0.97      3005\n",
      "        1.0       0.94      0.62      0.75       495\n",
      "\n",
      "avg / total       0.94      0.94      0.94      3500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2987   18]\n",
      " [ 187  308]]\n",
      "\n",
      "Average Accuracy:\t0.9029\n",
      "\n",
      "Standard Deviation:\t0.0136\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.9040\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.98      0.95      1288\n",
      "        1.0       0.77      0.46      0.57       212\n",
      "\n",
      "avg / total       0.90      0.90      0.89      1500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1259   29]\n",
      " [ 115   97]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(knn ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(knn ,X_train,y_train,X_test,y_test, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.8740\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.93      0.93      3005\n",
      "        1.0       0.56      0.55      0.55       495\n",
      "\n",
      "avg / total       0.87      0.87      0.87      3500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2788  217]\n",
      " [ 224  271]]\n",
      "\n",
      "Average Accuracy:\t0.8706\n",
      "\n",
      "Standard Deviation:\t0.0149\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.8733\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.93      0.93      1288\n",
      "        1.0       0.56      0.51      0.53       212\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1202   86]\n",
      " [ 104  108]]\n",
      "\n",
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.8551\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.97      0.92      3005\n",
      "        1.0       0.47      0.18      0.26       495\n",
      "\n",
      "avg / total       0.82      0.86      0.83      3500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2905  100]\n",
      " [ 407   88]]\n",
      "\n",
      "Average Accuracy:\t0.8552\n",
      "\n",
      "Standard Deviation:\t0.0127\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.8487\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.96      0.92      1288\n",
      "        1.0       0.40      0.15      0.21       212\n",
      "\n",
      "avg / total       0.81      0.85      0.82      1500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1242   46]\n",
      " [ 181   31]]\n",
      "\n",
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.8586\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      1.00      0.92      3005\n",
      "        1.0       0.00      0.00      0.00       495\n",
      "\n",
      "avg / total       0.74      0.86      0.79      3500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3005    0]\n",
      " [ 495    0]]\n",
      "\n",
      "Average Accuracy:\t0.8586\n",
      "\n",
      "Standard Deviation:\t0.0010\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.8587\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      1.00      0.92      1288\n",
      "        1.0       0.00      0.00      0.00       212\n",
      "\n",
      "avg / total       0.74      0.86      0.79      1500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1288    0]\n",
      " [ 212    0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(gnb ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(gnb ,X_train,y_train,X_test,y_test, train = False)\n",
    "print_score(bnb ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(bnb ,X_train,y_train,X_test,y_test, train = False)\n",
    "print_score(mnb ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(mnb ,X_train,y_train,X_test,y_test, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.8640\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.98      0.93      3005\n",
      "        1.0       0.57      0.16      0.24       495\n",
      "\n",
      "avg / total       0.83      0.86      0.83      3500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2947   58]\n",
      " [ 418   77]]\n",
      "\n",
      "Average Accuracy:\t0.8626\n",
      "\n",
      "Standard Deviation:\t0.0101\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.8727\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.99      0.93      1288\n",
      "        1.0       0.74      0.15      0.25       212\n",
      "\n",
      "avg / total       0.86      0.87      0.83      1500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1277   11]\n",
      " [ 180   32]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(logreg ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(logreg ,X_train,y_train,X_test,y_test, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training result:\n",
      "\n",
      "Accuracy Score: 0.9823\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      3005\n",
      "          1       1.00      0.87      0.93       495\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3005    0]\n",
      " [  62  433]]\n",
      "\n",
      "Average Accuracy:\t0.9357\n",
      "\n",
      "Standard Deviation:\t0.0121\n",
      "Test result:\n",
      "\n",
      "Accuracy Score: 0.9427\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97      1288\n",
      "          1       0.84      0.74      0.79       212\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1257   31]\n",
      " [  55  157]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(219, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(dt ,X_train,y_train,X_test,y_test, train = True)\n",
    "print_score(dt ,X_train,y_train,X_test,y_test, train = False)\n",
    "dt.tree_.node_count, dt.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
