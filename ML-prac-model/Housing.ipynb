{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wpghk\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 32182.654821228833\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "#Set data sets path here\n",
    "data_path = [r'C:\\Users\\wpghk\\ai_data']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "start = time()\n",
    "\n",
    "# Import the data using the file path\n",
    "filepath = os.sep.join(data_path + ['Ames_Housing_Sales.csv'])\n",
    "data = pd.read_csv(filepath, sep=',')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "# Get a Pd.Series consisting of all the string categoricals\n",
    "one_hot_encode_cols = data.dtypes[data.dtypes == np.object]  # filtering by string categoricals\n",
    "one_hot_encode_cols = one_hot_encode_cols.index.tolist()  # list of categorical fields\n",
    "\n",
    "# Here we see another way of one-hot-encoding:\n",
    "# Encode these columns as categoricals so one hot encoding works on split data (if desired)\n",
    "for col in one_hot_encode_cols:\n",
    "    data[col] = pd.Categorical(data[col])\n",
    "\n",
    "# Do the one hot encoding\n",
    "data = pd.get_dummies(data, columns=one_hot_encode_cols)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a list of float colums to check for skewing\n",
    "mask = data.dtypes == np.float\n",
    "float_cols = data.columns[mask]\n",
    "\n",
    "skew_limit = 0.75\n",
    "skew_vals = train[float_cols].skew()\n",
    "\n",
    "skew_cols = (skew_vals\n",
    "             .sort_values(ascending=False)\n",
    "             .to_frame()\n",
    "             .rename(columns={0:'Skew'})\n",
    "             .query('abs(Skew) > {0}'.format(skew_limit)))\n",
    "\n",
    "# Mute the setting wtih a copy warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "for col in skew_cols.index.tolist():\n",
    "    if col == \"SalePrice\":\n",
    "        continue\n",
    "    train[col] = np.log1p(train[col])\n",
    "    test[col]  = test[col].apply(np.log1p)  # same thing\n",
    "    \n",
    "feature_cols = [x for x in train.columns if x != 'SalePrice']\n",
    "X_train = train[feature_cols]\n",
    "y_train = train['SalePrice']\n",
    "\n",
    "X_test  = test[feature_cols]\n",
    "y_test  = test['SalePrice']\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def rmse(ytrue, ypredicted):\n",
    "    return np.sqrt(mean_squared_error(ytrue, ypredicted))\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "alphas = [0.005, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 80]\n",
    "\n",
    "ridgeCV = RidgeCV(alphas=alphas, \n",
    "                  cv=4).fit(X_train, y_train)\n",
    "\n",
    "ridgeCV_rmse = rmse(y_test, ridgeCV.predict(X_test))\n",
    "\n",
    "print(ridgeCV.alpha_, ridgeCV_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>Street</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>856.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>920.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  Alley  BedroomAbvGr  BldgType  BsmtCond  \\\n",
       "0     856.0     854.0        0.0      0             3         1         0   \n",
       "1    1262.0       0.0        0.0      0             3         1         0   \n",
       "2     920.0     866.0        0.0      0             3         1         0   \n",
       "3     961.0     756.0        0.0      0             3         1         0   \n",
       "4    1145.0    1053.0        0.0      0             4         1         0   \n",
       "\n",
       "   BsmtExposure  BsmtFinSF1  BsmtFinSF2    ...      ScreenPorch  Street  \\\n",
       "0             0       706.0         0.0    ...              0.0       1   \n",
       "1             0       978.0         0.0    ...              0.0       1   \n",
       "2             0       486.0         0.0    ...              0.0       1   \n",
       "3             0       216.0         0.0    ...              0.0       1   \n",
       "4             1       655.0         0.0    ...              0.0       1   \n",
       "\n",
       "   TotRmsAbvGrd  TotalBsmtSF  Utilities  WoodDeckSF  YearBuilt  YearRemodAdd  \\\n",
       "0             8        856.0          0         0.0       2003          2003   \n",
       "1             6       1262.0          0       298.0       1976          1976   \n",
       "2             6        920.0          0         0.0       2001          2002   \n",
       "3             7        756.0          0         0.0       1915          1970   \n",
       "4             9       1145.0          0       192.0       2000          2000   \n",
       "\n",
       "   YrSold  SalePrice  \n",
       "0    2008   208500.0  \n",
       "1    2007   181500.0  \n",
       "2    2008   223500.0  \n",
       "3    2006   140000.0  \n",
       "4    2008   250000.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a Pd.Series consisting of all the string categoricals\n",
    "cols = data.dtypes[data.dtypes == np.object]  # filtering by string categoricals\n",
    "cols = cols.index.tolist()  # list of categorical fields\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "for col in cols:\n",
    "    data[col] = lb.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of float colums to check for skewing\n",
    "mask = data.dtypes == np.float\n",
    "float_cols = data.columns[mask]\n",
    "skew_limit = 0.75\n",
    "skew_vals = train[float_cols].skew()\n",
    "\n",
    "skew_cols = (skew_vals\n",
    "             .sort_values(ascending=False)\n",
    "             .to_frame()\n",
    "             .rename(columns={0:'Skew'})\n",
    "             .query('abs(Skew) > {0}'.format(skew_limit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mute the setting wtih a copy warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "for col in skew_cols.index.tolist():\n",
    "    if col == \"SalePrice\":\n",
    "        continue\n",
    "    train[col] = np.log1p(train[col])\n",
    "    test[col]  = test[col].apply(np.log1p)  # same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [x for x in train.columns if x != 'SalePrice']\n",
    "X_train = train[feature_cols]\n",
    "y_train = train['SalePrice']\n",
    "\n",
    "X_test  = test[feature_cols]\n",
    "y_test  = test['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def rmse(ytrue, ypredicted):\n",
    "    return np.sqrt(mean_squared_error(ytrue, ypredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35522.01286126253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linearRegression = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "linearRegression_rmse = rmse(y_test, linearRegression.predict(X_test))\n",
    "\n",
    "print(linearRegression_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 34966.48813253083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "alphas = [0.005, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 80]\n",
    "\n",
    "ridgeCV = RidgeCV(alphas=alphas, \n",
    "                  cv=4).fit(X_train, y_train)\n",
    "\n",
    "ridgeCV_rmse = rmse(y_test, ridgeCV.predict(X_test))\n",
    "\n",
    "print(ridgeCV.alpha_, ridgeCV_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wpghk\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005 35522.0074735711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "alphas2 = np.array([1e-5, 5e-5, 0.0001, 0.0005])\n",
    "\n",
    "lassoCV = LassoCV(alphas=alphas2,\n",
    "                  max_iter=5e4,\n",
    "                  cv=3).fit(X_train, y_train)\n",
    "\n",
    "lassoCV_rmse = rmse(y_test, lassoCV.predict(X_test))\n",
    "\n",
    "print(lassoCV.alpha_, lassoCV_rmse)  # Lasso is slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest = RandomForestRegressor(random_state = 42, n_jobs =-1)\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39075.84155449911"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_rmse = rmse(y_test, random_forest.predict(X_test))\n",
    "random_forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=26, presort='auto', random_state=42,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(n_estimators=120, random_state=42)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [rmse(y_test, y_pred)\n",
    "          for y_pred in gbrt.staged_predict(X_test)]\n",
    "bst_n_estimators = np.argmin(errors)\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators, random_state=42)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36222.988827526045"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_rmse = rmse(y_test, gbrt_best.predict(X_test))\n",
    "random_forest_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alphas2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-794ce0371ce4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ml1_ratios\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m elasticNetCV = ElasticNetCV(alphas=alphas2, \n\u001b[0m\u001b[0;32m      6\u001b[0m                             \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml1_ratios\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                             max_iter=1e4).fit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alphas2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "l1_ratios = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "elasticNetCV = ElasticNetCV(alphas=alphas2, \n",
    "                            l1_ratio=l1_ratios,\n",
    "                            max_iter=1e4).fit(X_train, y_train)\n",
    "elasticNetCV_rmse = rmse(y_test, elasticNetCV.predict(X_test))\n",
    "\n",
    "print(elasticNetCV.alpha_, elasticNetCV.l1_ratio_, elasticNetCV_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=0.01, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svm_reg = LinearSVR(epsilon = 0.01)\n",
    "svm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58527.75584652284"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_rmse = rmse(y_test, svm_reg.predict(X_test))\n",
    "random_forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, cache_size=200, coef0=0.0, degree=2, epsilon=0.1, gamma='auto',\n",
       "  kernel='poly', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_p_reg = SVR(kernel = 'poly', degree = 2, C = 100, epsilon = 0.1)\n",
    "svm_p_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120465.96062074699"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_rmse = rmse(y_test, svm_p_reg.predict(X_test))\n",
    "random_forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state = 42)\n",
    "tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43355.05001284097"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_rmse = rmse(y_test, tree.predict(X_test))\n",
    "random_forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
